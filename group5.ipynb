{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3f207db",
   "metadata": {},
   "source": [
    "# Energy Anomaly & Automated Power Theft Detection System  \n",
    "### A Data Science Research Framework for Context-Aware Grid Intelligence\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "Electricity utilities in **Kenya** face significant financial and operational strain due to non-technical losses arising from electricity theft, meter tampering, illegal connections, and irregular consumption behavior. While smart meter infrastructure generates large volumes of high-frequency time-series data, many utilities lack intelligent systems capable of converting raw consumption signals into actionable risk alerts.\n",
    "\n",
    "This project develops an end-to-end data science framework that not only detects abnormal electricity usage patterns but also generates structured, automated risk notifications suitable for investigation workflows.\n",
    "\n",
    "To simulate a realistic operational environment, a multi-household electricity dataset is constructed using high-resolution consumption measurements. Natural behavioral variability is preserved across households, while selected households are injected with synthetic theft-like patterns such as sustained consumption drops and altered load distributions. This enables controlled validation of anomaly detection techniques in the absence of real labeled fraud data.\n",
    "\n",
    "The system integrates three core data layers:\n",
    "\n",
    "1. **Electricity Consumption Data (Behavioral Signal Layer)**  \n",
    "   Minute-level power and voltage readings aggregated into structured daily behavioral indicators.\n",
    "\n",
    "2. **Weather Data (Environmental Context Layer)**  \n",
    "   Temperature, precipitation, and wind speed variables used to explain legitimate demand variability and reduce false anomaly detection.\n",
    "\n",
    "3. **Scheduled Outage Information (Operational Filter Layer)**  \n",
    "   Official maintenance interruption records structured into daily indicators to prevent misclassification of planned supply disruptions.\n",
    "\n",
    "The analytical pipeline transitions from raw time-series inputs to a structured intelligence system that:\n",
    "\n",
    "- Engineers behavioral and change-based features  \n",
    "- Adjusts signals using environmental and operational context  \n",
    "- Applies unsupervised anomaly detection techniques  \n",
    "- Assigns quantitative theft-risk scores  \n",
    "- Triggers automated structured notification outputs for high-risk cases  \n",
    "\n",
    "The final system moves beyond static classification by producing prioritized, investigation-ready alerts supported by explainable risk indicators. This framework demonstrates how utilities can transition from reactive inspection-based fraud handling to proactive, data-driven anomaly intelligence with automated alert generation.\n",
    "\n",
    "---\n",
    "\n",
    "## Business Problem\n",
    "\n",
    "Electricity utilities operate in environments where revenue protection, grid reliability, and operational efficiency are critical. A major persistent challenge is the presence of non-technical losses caused by electricity theft and irregular consumption behavior.\n",
    "\n",
    "These losses:\n",
    "\n",
    "- Reduce utility revenue  \n",
    "- Increase operational and inspection costs  \n",
    "- Introduce uneven demand stress on distribution infrastructure  \n",
    "- Compromise grid stability  \n",
    "\n",
    "Traditional fraud detection approaches rely on:\n",
    "\n",
    "- Manual inspections  \n",
    "- Customer complaints  \n",
    "- Rule-based heuristics  \n",
    "\n",
    "These methods are reactive, costly, and inefficient.\n",
    "\n",
    "Although smart meters provide high-frequency consumption data, most utilities lack structured systems capable of distinguishing legitimate variability (e.g., weather shifts, seasonal effects, scheduled outages) from suspicious behavioral anomalies. Furthermore, even when anomalies are detected, many utilities lack automated mechanisms to translate analytical outputs into actionable investigation alerts.\n",
    "\n",
    "The central business problem addressed in this project is:\n",
    "\n",
    "> How can utilities leverage integrated consumption, environmental, and operational data to proactively detect abnormal electricity behavior and automatically generate structured investigation notifications?\n",
    "\n",
    "Specifically, the challenge involves:\n",
    "\n",
    "- Detecting anomalous patterns without fully labeled theft data  \n",
    "- Minimizing false positives caused by legitimate variability  \n",
    "- Translating anomaly scores into explainable risk indicators  \n",
    "- Automatically producing structured alerts to support investigation workflows  \n",
    "- Designing a scalable, context-aware detection framework suitable for operational deployment  \n",
    "\n",
    "This project addresses these challenges by developing a layered anomaly detection system with an embedded automated notification mechanism that flags high-risk consumption cases.\n",
    "\n",
    "---\n",
    "\n",
    "## Project Objectives\n",
    "\n",
    "The primary objective of this project is to design, implement, and evaluate a context-aware anomaly detection framework capable of identifying potential power theft and generating automated risk notifications using time-series smart meter data.\n",
    "\n",
    "### 1 Data Preparation & Simulation\n",
    "\n",
    "- Construct a multi-household electricity consumption dataset from high-frequency readings.\n",
    "- Introduce controlled behavioral diversity across simulated households.\n",
    "- Inject theft-like consumption patterns to enable controlled anomaly validation.\n",
    "\n",
    "### 2 Feature Engineering\n",
    "\n",
    "- Aggregate minute-level consumption into structured daily indicators.\n",
    "- Engineer statistical and volatility-based features.\n",
    "- Create change-based indicators (rolling averages, percentage shifts).\n",
    "- Integrate weather variables for contextual adjustment.\n",
    "- Incorporate scheduled outage indicators as operational filters.\n",
    "\n",
    "### 3 Anomaly Detection Modeling\n",
    "\n",
    "- Apply unsupervised anomaly detection techniques (e.g., Isolation Forest).\n",
    "- Generate quantitative anomaly scores per household-day.\n",
    "- Define risk thresholds to classify consumption into Low, Medium, and High-risk categories.\n",
    "\n",
    "### 4 Evaluation & Validation\n",
    "\n",
    "- Measure detection consistency across simulated theft scenarios.\n",
    "- Analyze false positives resulting from weather or outage effects.\n",
    "- Assess stability of anomaly detection across heterogeneous households.\n",
    "\n",
    "### 5 Automated Risk Notification Layer\n",
    "\n",
    "- Develop a structured alert-generation mechanism triggered by defined anomaly thresholds.\n",
    "- Create investigation-ready outputs including:\n",
    "  - Meter ID\n",
    "  - Date\n",
    "  - Risk score\n",
    "  - Risk category\n",
    "  - Supporting behavioral indicators\n",
    "- Demonstrate how anomaly detection outputs can feed into downstream notification workflows (e.g., case export, dashboard alerting, automated email triggers).\n",
    "Through these objectives, the project demonstrates how integrated data science techniques can power a proactive energy irregularity detection system that combines anomaly modeling with automated alert generation.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e965dbd",
   "metadata": {},
   "source": [
    "## Research Phase I â€” Anomaly Detection Engine Development (LEAD Dataset)\n",
    "\n",
    "### Objective\n",
    "\n",
    "Before deploying the electricity theft detection system on the Kenya dataset, we first develop and validate a robust anomaly detection engine using the LEAD (Large-scale Energy Anomaly Detection) dataset.\n",
    "\n",
    "The LEAD dataset contains hourly smart meter readings from multiple buildings, along with labeled anomaly events. This makes it ideal for calibrating anomaly detection algorithms and evaluating performance before production deployment.\n",
    "\n",
    "---\n",
    "\n",
    "### Why We Start With LEAD\n",
    "\n",
    "The Kenya deployment dataset does not contain confirmed theft labels. Therefore, building a model directly on it would make it difficult to evaluate performance objectively.\n",
    "\n",
    "Using LEAD allows us to:\n",
    "\n",
    "- Validate anomaly detection techniques on labeled data\n",
    "- Evaluate precision and recall of detected anomalies\n",
    "- Tune model parameters appropriately\n",
    "- Avoid overfitting or under-sensitive detection in production\n",
    "\n",
    "---\n",
    "\n",
    "### What We Will Do in This Phase\n",
    "\n",
    "1. Load and inspect the dataset structure  \n",
    "2. Assess anomaly class imbalance  \n",
    "3. Handle missing values  \n",
    "4. Engineer time-based features  \n",
    "5. Build an anomaly detection model (Isolation Forest)  \n",
    "6. Evaluate model performance using anomaly labels  \n",
    "\n",
    "---\n",
    "\n",
    "### Expected Outcome\n",
    "\n",
    "At the end of this phase, we will have:\n",
    "\n",
    "- A validated anomaly detection engine  \n",
    "- Performance metrics (precision, recall, F1-score)  \n",
    "- A calibrated detection threshold  \n",
    "- A robust foundation for deployment in the Kenya electricity theft detection system  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a458c522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id            timestamp  meter_reading  anomaly\n",
       "0            1  2016-01-01 00:00:00            NaN        0\n",
       "1           32  2016-01-01 00:00:00            NaN        0\n",
       "2           41  2016-01-01 00:00:00            NaN        0\n",
       "3           55  2016-01-01 00:00:00            NaN        0\n",
       "4           69  2016-01-01 00:00:00            NaN        0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lead_df = pd.read_csv(\"lead1.0-small.csv\")\n",
    "\n",
    "lead_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8e5c910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1749494 entries, 0 to 1749493\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   building_id    int64  \n",
      " 1   timestamp      object \n",
      " 2   meter_reading  float64\n",
      " 3   anomaly        int64  \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 53.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead_df.info()\n",
    "lead_df.isnull().sum()\n",
    "lead_df[\"anomaly\"].value_counts()\n",
    "lead_df[\"building_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5e7077c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing % in meter_reading: 6.15 %\n",
      "\n",
      "Anomaly distribution:\n",
      "anomaly\n",
      "0    97.868184\n",
      "1     2.131816\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  timestamp  meter_reading  anomaly\n",
       "0            1 2016-01-01            NaN        0\n",
       "1           32 2016-01-01            NaN        0\n",
       "2           41 2016-01-01            NaN        0\n",
       "3           55 2016-01-01            NaN        0\n",
       "4           69 2016-01-01            NaN        0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert timestamp to datetime\n",
    "lead_df[\"timestamp\"] = pd.to_datetime(lead_df[\"timestamp\"])\n",
    "\n",
    "# Check missing percentage\n",
    "missing_percent = lead_df[\"meter_reading\"].isna().mean() * 100\n",
    "print(\"Missing % in meter_reading:\", round(missing_percent, 2), \"%\")\n",
    "\n",
    "# Anomaly distribution\n",
    "print(\"\\nAnomaly distribution:\")\n",
    "print(lead_df[\"anomaly\"].value_counts(normalize=True) * 100)\n",
    "\n",
    "lead_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a99ca3",
   "metadata": {},
   "source": [
    "## Data Cleaning and Time-Series Preparation\n",
    "\n",
    "The LEAD dataset contains approximately 6.15% missing values in the `meter_reading` column. Since this dataset represents hourly time-series data, dropping rows could disrupt temporal continuity.\n",
    "\n",
    "Therefore, we perform:\n",
    "\n",
    "- Sorting by `building_id` and `timestamp`\n",
    "- Group-based interpolation to preserve temporal structure\n",
    "- Validation to ensure missing values are resolved appropriately\n",
    "\n",
    "Maintaining time-series integrity is critical for anomaly detection performance, especially when using models such as Isolation Forest that rely on consistent feature distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f863ce76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining missing: 28026\n"
     ]
    }
   ],
   "source": [
    "# Sort properly\n",
    "lead_df = lead_df.sort_values([\"building_id\", \"timestamp\"])\n",
    "\n",
    "# Interpolate missing meter readings per building\n",
    "lead_df[\"meter_reading\"] = (\n",
    "    lead_df.groupby(\"building_id\")[\"meter_reading\"]\n",
    "    .transform(lambda x: x.interpolate(method=\"linear\"))\n",
    ")\n",
    "\n",
    "# Check remaining missing values\n",
    "print(\"Remaining missing:\", lead_df[\"meter_reading\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e7559a",
   "metadata": {},
   "source": [
    "### Handling Edge Missing Values\n",
    "\n",
    "After interpolation, some missing values remain at the beginning or end of building time series. These occur because interpolation requires surrounding values.\n",
    "\n",
    "To preserve time continuity, we apply forward-fill and backward-fill within each building group. This ensures complete time-series integrity before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ff41071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining missing after fill: 0\n"
     ]
    }
   ],
   "source": [
    "# Forward fill per building\n",
    "lead_df[\"meter_reading\"] = (\n",
    "    lead_df.groupby(\"building_id\")[\"meter_reading\"]\n",
    "    .transform(lambda x: x.ffill().bfill())\n",
    ")\n",
    "\n",
    "# Final check\n",
    "print(\"Remaining missing after fill:\", lead_df[\"meter_reading\"].isna().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
