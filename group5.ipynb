{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3f207db",
   "metadata": {},
   "source": [
    "# Energy Anomaly & Automated Power Theft Detection System  \n",
    "### A Data Science Research Framework for Context-Aware Grid Intelligence\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "Electricity utilities in **Kenya** face significant financial and operational strain due to non-technical losses arising from electricity theft, meter tampering, illegal connections, and irregular consumption behavior. While smart meter infrastructure generates large volumes of high-frequency time-series data, many utilities lack intelligent systems capable of converting raw consumption signals into actionable risk alerts.\n",
    "\n",
    "This project develops an end-to-end data science framework that not only detects abnormal electricity usage patterns but also generates structured, automated risk notifications suitable for investigation workflows.\n",
    "\n",
    "To simulate a realistic operational environment, a multi-household electricity dataset is constructed using high-resolution consumption measurements. Natural behavioral variability is preserved across households, while selected households are injected with synthetic theft-like patterns such as sustained consumption drops and altered load distributions. This enables controlled validation of anomaly detection techniques in the absence of real labeled fraud data.\n",
    "\n",
    "The system integrates three core data layers:\n",
    "\n",
    "1. **Electricity Consumption Data (Behavioral Signal Layer)**  \n",
    "   Minute-level power and voltage readings aggregated into structured daily behavioral indicators.\n",
    "\n",
    "2. **Weather Data (Environmental Context Layer)**  \n",
    "   Temperature, precipitation, and wind speed variables used to explain legitimate demand variability and reduce false anomaly detection.\n",
    "\n",
    "3. **Scheduled Outage Information (Operational Filter Layer)**  \n",
    "   Official maintenance interruption records structured into daily indicators to prevent misclassification of planned supply disruptions.\n",
    "\n",
    "The analytical pipeline transitions from raw time-series inputs to a structured intelligence system that:\n",
    "\n",
    "- Engineers behavioral and change-based features  \n",
    "- Adjusts signals using environmental and operational context  \n",
    "- Applies unsupervised anomaly detection techniques  \n",
    "- Assigns quantitative theft-risk scores  \n",
    "- Triggers automated structured notification outputs for high-risk cases  \n",
    "\n",
    "The final system moves beyond static classification by producing prioritized, investigation-ready alerts supported by explainable risk indicators. This framework demonstrates how utilities can transition from reactive inspection-based fraud handling to proactive, data-driven anomaly intelligence with automated alert generation.\n",
    "\n",
    "---\n",
    "\n",
    "## Business Problem\n",
    "\n",
    "Electricity utilities operate in environments where revenue protection, grid reliability, and operational efficiency are critical. A major persistent challenge is the presence of non-technical losses caused by electricity theft and irregular consumption behavior.\n",
    "\n",
    "These losses:\n",
    "\n",
    "- Reduce utility revenue  \n",
    "- Increase operational and inspection costs  \n",
    "- Introduce uneven demand stress on distribution infrastructure  \n",
    "- Compromise grid stability  \n",
    "\n",
    "Traditional fraud detection approaches rely on:\n",
    "\n",
    "- Manual inspections  \n",
    "- Customer complaints  \n",
    "- Rule-based heuristics  \n",
    "\n",
    "These methods are reactive, costly, and inefficient.\n",
    "\n",
    "Although smart meters provide high-frequency consumption data, most utilities lack structured systems capable of distinguishing legitimate variability (e.g., weather shifts, seasonal effects, scheduled outages) from suspicious behavioral anomalies. Furthermore, even when anomalies are detected, many utilities lack automated mechanisms to translate analytical outputs into actionable investigation alerts.\n",
    "\n",
    "The central business problem addressed in this project is:\n",
    "\n",
    "> How can utilities leverage integrated consumption, environmental, and operational data to proactively detect abnormal electricity behavior and automatically generate structured investigation notifications?\n",
    "\n",
    "Specifically, the challenge involves:\n",
    "\n",
    "- Detecting anomalous patterns without fully labeled theft data  \n",
    "- Minimizing false positives caused by legitimate variability  \n",
    "- Translating anomaly scores into explainable risk indicators  \n",
    "- Automatically producing structured alerts to support investigation workflows  \n",
    "- Designing a scalable, context-aware detection framework suitable for operational deployment  \n",
    "\n",
    "This project addresses these challenges by developing a layered anomaly detection system with an embedded automated notification mechanism that flags high-risk consumption cases.\n",
    "\n",
    "---\n",
    "\n",
    "## Project Objectives\n",
    "\n",
    "The primary objective of this project is to design, implement, and evaluate a context-aware anomaly detection framework capable of identifying potential power theft and generating automated risk notifications using time-series smart meter data.\n",
    "\n",
    "### 1 Data Preparation & Simulation\n",
    "\n",
    "- Construct a multi-household electricity consumption dataset from high-frequency readings.\n",
    "- Introduce controlled behavioral diversity across simulated households.\n",
    "- Inject theft-like consumption patterns to enable controlled anomaly validation.\n",
    "\n",
    "### 2 Feature Engineering\n",
    "\n",
    "- Aggregate minute-level consumption into structured daily indicators.\n",
    "- Engineer statistical and volatility-based features.\n",
    "- Create change-based indicators (rolling averages, percentage shifts).\n",
    "- Integrate weather variables for contextual adjustment.\n",
    "- Incorporate scheduled outage indicators as operational filters.\n",
    "\n",
    "### 3 Anomaly Detection Modeling\n",
    "\n",
    "- Apply unsupervised anomaly detection techniques (e.g., Isolation Forest).\n",
    "- Generate quantitative anomaly scores per household-day.\n",
    "- Define risk thresholds to classify consumption into Low, Medium, and High-risk categories.\n",
    "\n",
    "### 4 Evaluation & Validation\n",
    "\n",
    "- Measure detection consistency across simulated theft scenarios.\n",
    "- Analyze false positives resulting from weather or outage effects.\n",
    "- Assess stability of anomaly detection across heterogeneous households.\n",
    "\n",
    "### 5 Automated Risk Notification Layer\n",
    "\n",
    "- Develop a structured alert-generation mechanism triggered by defined anomaly thresholds.\n",
    "- Create investigation-ready outputs including:\n",
    "  - Meter ID\n",
    "  - Date\n",
    "  - Risk score\n",
    "  - Risk category\n",
    "  - Supporting behavioral indicators\n",
    "- Demonstrate how anomaly detection outputs can feed into downstream notification workflows (e.g., case export, dashboard alerting, automated email triggers).\n",
    "\n",
    "---\n",
    "\n",
    "Through these objectives, the project demonstrates how integrated data science techniques can power a proactive energy irregularity detection system that combines anomaly modeling with automated alert generation.\n",
    "\n",
    "---\n",
    "\n",
    "## Role of Each Dataset in the Detection & Notification Framework\n",
    "\n",
    "This project operates on three primary datasets that collectively enable context-aware detection and automated notification.\n",
    "\n",
    "---\n",
    "\n",
    "### 1 Multi-Household Daily Electricity Dataset  \n",
    "**(power_multi_household_daily.csv)**  \n",
    "\n",
    "This dataset forms the core behavioral signal layer.\n",
    "\n",
    "It provides:\n",
    "\n",
    "- Daily consumption patterns per meter  \n",
    "- Load variability indicators  \n",
    "- Voltage stability metrics  \n",
    "- Behavioral change signals  \n",
    "\n",
    "This dataset feeds directly into anomaly scoring and risk assessment.\n",
    "\n",
    "---\n",
    "\n",
    "### 2 Weather Context Dataset  \n",
    "**(nairobi_weather_2007_2008.csv)**  \n",
    "\n",
    "This dataset adds environmental context to the system.\n",
    "\n",
    "It helps:\n",
    "\n",
    "- Adjust for temperature-driven demand shifts  \n",
    "- Account for rainfall and wind-related variability  \n",
    "- Reduce false detection rates  \n",
    "\n",
    "It strengthens the robustness of anomaly classification.\n",
    "\n",
    "---\n",
    "\n",
    "### 3 Scheduled Outage Dataset  \n",
    "**(kplc_daily_schedule.csv)**  \n",
    "\n",
    "This dataset acts as an operational safeguard.\n",
    "\n",
    "It:\n",
    "\n",
    "- Flags days with planned interruptions  \n",
    "- Prevents misclassification of legitimate low-consumption periods  \n",
    "- Enhances contextual accuracy  \n",
    "\n",
    "---\n",
    "\n",
    "## Integrated System Architecture\n",
    "\n",
    "The detection framework follows a layered structure:\n",
    "\n",
    "- **Behavioral Signal Layer → Consumption Features**\n",
    "- **Environmental Context Layer → Weather Adjustment**\n",
    "- **Operational Filter Layer → Outage Awareness**\n",
    "- **Anomaly Modeling Layer → Risk Scoring**\n",
    "- **Notification Layer → Automated Alert Generation**\n",
    "\n",
    "By combining these layers, the system produces prioritized, explainable risk alerts that can trigger automated notifications and support investigation workflows.\n",
    "\n",
    "This integrated design enhances detection reliability while minimizing false alarms, presenting a scalable blueprint for intelligent, automated energy irregularity monitoring systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2a3e04",
   "metadata": {},
   "source": [
    "## Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e758bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily_df shape: (14420, 9)\n",
      "weather_df shape: (731, 5)\n",
      "kplc_df shape: (5, 4)\n",
      "\n",
      "Daily columns: ['meter_id', 'date', 'daily_mean_power', 'daily_std_power', 'daily_min_power', 'daily_max_power', 'voltage_mean', 'voltage_std', 'intensity_mean']\n",
      "\n",
      "Weather columns: ['date', 'tmax', 'tmin', 'prcp', 'wspd_max']\n",
      "\n",
      "KPLC columns: ['date', 'scheduled_outage_today', 'n_scheduled_events', 'total_scheduled_minutes']\n",
      "\n",
      "Date dtypes:\n",
      "daily_df date dtype: datetime64[ns]\n",
      "weather_df date dtype: datetime64[ns]\n",
      "kplc_df date dtype: datetime64[ns]\n",
      "\n",
      "Date ranges:\n",
      "Power: 2006-12-16 00:00:00 to 2010-11-26 00:00:00\n",
      "Weather: 2007-01-01 00:00:00 to 2008-12-31 00:00:00\n",
      "KPLC: 2026-01-18 00:00:00 to 2026-01-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "daily_df = pd.read_csv(\"power_multi_household_daily.csv\", parse_dates=[\"date\"])\n",
    "weather_df = pd.read_csv(\"nairobi_weather_2007_2008.csv\", parse_dates=[\"date\"])\n",
    "kplc_df = pd.read_csv(\"kplc_daily_schedule.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "print(\"daily_df shape:\", daily_df.shape)\n",
    "print(\"weather_df shape:\", weather_df.shape)\n",
    "print(\"kplc_df shape:\", kplc_df.shape)\n",
    "\n",
    "print(\"\\nDaily columns:\", list(daily_df.columns))\n",
    "print(\"\\nWeather columns:\", list(weather_df.columns))\n",
    "print(\"\\nKPLC columns:\", list(kplc_df.columns))\n",
    "\n",
    "print(\"\\nDate dtypes:\")\n",
    "print(\"daily_df date dtype:\", daily_df[\"date\"].dtype)\n",
    "print(\"weather_df date dtype:\", weather_df[\"date\"].dtype)\n",
    "print(\"kplc_df date dtype:\", kplc_df[\"date\"].dtype)\n",
    "\n",
    "print(\"\\nDate ranges:\")\n",
    "print(\"Power:\", daily_df[\"date\"].min(), \"to\", daily_df[\"date\"].max())\n",
    "print(\"Weather:\", weather_df[\"date\"].min(), \"to\", weather_df[\"date\"].max())\n",
    "print(\"KPLC:\", kplc_df[\"date\"].min(), \"to\", kplc_df[\"date\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b5605f",
   "metadata": {},
   "source": [
    "## Merge Power and Weather Data\n",
    "\n",
    "To ensure temporal consistency, we merge the daily electricity dataset with the weather dataset using an inner join on the `date` column. \n",
    "\n",
    "This restricts the modeling period to the overlapping years (2007–2008), ensuring environmental context is available for every consumption record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36115677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merge shape: (7310, 13)\n",
      "\n",
      "Date range after merge:\n",
      "2007-01-01 00:00:00 to 2008-12-31 00:00:00\n",
      "\n",
      "Missing weather values:\n",
      "tmax        0\n",
      "tmin        0\n",
      "prcp        0\n",
      "wspd_max    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Merge power + weather (inner join keeps only overlapping dates)\n",
    "model_df = daily_df.merge(weather_df, on=\"date\", how=\"inner\")\n",
    "\n",
    "# Check new dataset structure\n",
    "print(\"After merge shape:\", model_df.shape)\n",
    "\n",
    "print(\"\\nDate range after merge:\")\n",
    "print(model_df[\"date\"].min(), \"to\", model_df[\"date\"].max())\n",
    "\n",
    "print(\"\\nMissing weather values:\")\n",
    "print(model_df[[\"tmax\", \"tmin\", \"prcp\", \"wspd_max\"]].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f02ca8a",
   "metadata": {},
   "source": [
    "## Validate Merged Dataset Integrity\n",
    "\n",
    "We verify:\n",
    "- No missing values in core behavioral fields\n",
    "- Each meter retains a full time series across the modeling window\n",
    "- The dataset structure remains stable after merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6503d3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values per column:\n",
      "daily_mean_power    10\n",
      "daily_min_power     10\n",
      "daily_std_power     10\n",
      "voltage_mean        10\n",
      "daily_max_power     10\n",
      "voltage_std         10\n",
      "intensity_mean      10\n",
      "date                 0\n",
      "meter_id             0\n",
      "tmax                 0\n",
      "tmin                 0\n",
      "prcp                 0\n",
      "wspd_max             0\n",
      "dtype: int64\n",
      "\n",
      "Number of unique meters:\n",
      "10\n",
      "\n",
      "Rows per meter (first 5):\n",
      "meter_id\n",
      "MTR_001    731\n",
      "MTR_002    731\n",
      "MTR_003    731\n",
      "MTR_004    731\n",
      "MTR_005    731\n",
      "dtype: int64\n",
      "\n",
      "Minimum rows for any meter: 731\n",
      "Maximum rows for any meter: 731\n"
     ]
    }
   ],
   "source": [
    "# Check overall missing values\n",
    "print(\"Total missing values per column:\")\n",
    "print(model_df.isna().sum().sort_values(ascending=False))\n",
    "\n",
    "# Confirm number of meters\n",
    "print(\"\\nNumber of unique meters:\")\n",
    "print(model_df[\"meter_id\"].nunique())\n",
    "\n",
    "# Quick rows per meter check\n",
    "rows_per_meter = model_df.groupby(\"meter_id\").size()\n",
    "print(\"\\nRows per meter (first 5):\")\n",
    "print(rows_per_meter.head())\n",
    "\n",
    "print(\"\\nMinimum rows for any meter:\", rows_per_meter.min())\n",
    "print(\"Maximum rows for any meter:\", rows_per_meter.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881bf023",
   "metadata": {},
   "source": [
    "## Remove Incomplete Behavioral Records\n",
    "\n",
    "A small number of rows contain missing core consumption values.\n",
    "To preserve anomaly detection integrity, these incomplete records are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efb220c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping incomplete rows: (7300, 13)\n",
      "\n",
      "Remaining missing values:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where key behavioral signals are missing\n",
    "model_df = model_df.dropna(subset=[\n",
    "    \"daily_mean_power\",\n",
    "    \"daily_std_power\",\n",
    "    \"daily_min_power\",\n",
    "    \"daily_max_power\",\n",
    "    \"voltage_mean\",\n",
    "    \"voltage_std\",\n",
    "    \"intensity_mean\"\n",
    "])\n",
    "\n",
    "print(\"Shape after dropping incomplete rows:\", model_df.shape)\n",
    "\n",
    "print(\"\\nRemaining missing values:\")\n",
    "print(model_df.isna().sum().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
