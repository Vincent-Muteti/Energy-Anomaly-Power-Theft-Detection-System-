{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d4127ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: meteostat in c:\\users\\moringa school\\anaconda3\\envs\\learn-env\\lib\\site-packages (1.6.5)\n",
      "Requirement already satisfied: pandas>=1.1 in c:\\users\\moringa school\\anaconda3\\envs\\learn-env\\lib\\site-packages (from meteostat) (2.3.2)\n",
      "Requirement already satisfied: pytz in c:\\users\\moringa school\\anaconda3\\envs\\learn-env\\lib\\site-packages (from meteostat) (2023.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\moringa school\\anaconda3\\envs\\learn-env\\lib\\site-packages (from meteostat) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\moringa school\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=1.1->meteostat) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\moringa school\\anaconda3\\envs\\learn-env\\lib\\site-packages (from pandas>=1.1->meteostat) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\moringa school\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas>=1.1->meteostat) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install meteostat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4798768a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'NaN' from 'numpy' (c:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\numpy\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point, Daily\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Nairobi coordinates\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\__init__.py:18\u001b[39m\n\u001b[32m     15\u001b[39m __version__ = \u001b[33m\"\u001b[39m\u001b[33m1.6.5\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Base\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtimeseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSeries\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Stations\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\interface\\timeseries.py:25\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmeteodata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MeteoData\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mTimeSeries\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mMeteoData\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[33;43;03m    TimeSeries class which provides features which are\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[33;43;03m    used across all time series classes\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[33;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The list of origin weather Stations\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\interface\\timeseries.py:196\u001b[39m, in \u001b[36mTimeSeries\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    193\u001b[39m         \u001b[38;5;28mself\u001b[39m.clear_cache()\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Import methods\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnormalize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m normalize\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterpolate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interpolate\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maggregate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m aggregate\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\series\\normalize.py:12\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mNormalize Data\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03mThe code is licensed under the MIT license.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcopy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m copy\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NaN\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytz\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'NaN' from 'numpy' (c:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\numpy\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from meteostat import Point, Daily\n",
    "from datetime import datetime\n",
    "\n",
    "# Nairobi coordinates\n",
    "nairobi = Point(-1.2921, 36.8219)\n",
    "\n",
    "start = datetime(2007, 1, 1)\n",
    "end = datetime(2008, 12, 31)\n",
    "\n",
    "data = Daily(nairobi, start, end)\n",
    "weather_df = data.fetch()\n",
    "\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff3c42b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c:\\Users\\Moringa' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade meteostat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5e2168b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'NaN' from 'numpy' (c:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\numpy\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Daily\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\__init__.py:18\u001b[39m\n\u001b[32m     15\u001b[39m __version__ = \u001b[33m\"\u001b[39m\u001b[33m1.6.5\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Base\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtimeseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSeries\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Stations\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\interface\\timeseries.py:25\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmeteodata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MeteoData\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mTimeSeries\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mMeteoData\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[33;43;03m    TimeSeries class which provides features which are\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[33;43;03m    used across all time series classes\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[33;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The list of origin weather Stations\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\interface\\timeseries.py:196\u001b[39m, in \u001b[36mTimeSeries\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    193\u001b[39m         \u001b[38;5;28mself\u001b[39m.clear_cache()\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Import methods\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnormalize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m normalize\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterpolate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interpolate\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maggregate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m aggregate\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\series\\normalize.py:12\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mNormalize Data\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03mThe code is licensed under the MIT license.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcopy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m copy\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NaN\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytz\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'NaN' from 'numpy' (c:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\numpy\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from meteostat import Point\n",
    "from meteostat import Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b55c3956",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'NaN' from 'numpy' (c:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\numpy\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(meteostat.__version__)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(meteostat.\u001b[34m__file__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\__init__.py:18\u001b[39m\n\u001b[32m     15\u001b[39m __version__ = \u001b[33m\"\u001b[39m\u001b[33m1.6.5\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Base\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtimeseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSeries\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Stations\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\interface\\timeseries.py:25\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmeteodata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MeteoData\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mTimeSeries\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mMeteoData\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[33;43;03m    TimeSeries class which provides features which are\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[33;43;03m    used across all time series classes\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[33;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The list of origin weather Stations\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\interface\\timeseries.py:196\u001b[39m, in \u001b[36mTimeSeries\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    193\u001b[39m         \u001b[38;5;28mself\u001b[39m.clear_cache()\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Import methods\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnormalize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m normalize\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterpolate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interpolate\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maggregate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m aggregate\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\series\\normalize.py:12\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mNormalize Data\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03mThe code is licensed under the MIT license.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcopy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m copy\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NaN\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytz\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'NaN' from 'numpy' (c:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\numpy\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import meteostat\n",
    "print(meteostat.__version__)\n",
    "print(meteostat.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cbf2d89",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'NaN' from 'numpy' (c:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\numpy\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mms\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m date\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Nairobi point\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\__init__.py:18\u001b[39m\n\u001b[32m     15\u001b[39m __version__ = \u001b[33m\"\u001b[39m\u001b[33m1.6.5\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Base\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtimeseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSeries\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Stations\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\interface\\timeseries.py:25\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmeteodata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MeteoData\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mTimeSeries\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mMeteoData\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[33;43;03m    TimeSeries class which provides features which are\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[33;43;03m    used across all time series classes\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[33;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The list of origin weather Stations\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\interface\\timeseries.py:196\u001b[39m, in \u001b[36mTimeSeries\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    193\u001b[39m         \u001b[38;5;28mself\u001b[39m.clear_cache()\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Import methods\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnormalize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m normalize\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterpolate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interpolate\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maggregate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m aggregate\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\series\\normalize.py:12\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mNormalize Data\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03mThe code is licensed under the MIT license.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcopy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m copy\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NaN\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytz\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'NaN' from 'numpy' (c:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\numpy\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import meteostat as ms\n",
    "from datetime import date\n",
    "\n",
    "# Nairobi point\n",
    "nairobi = ms.Point(-1.2921, 36.8219)\n",
    "\n",
    "start = date(2007, 1, 1)\n",
    "end   = date(2008, 12, 31)\n",
    "\n",
    "ts = ms.daily(nairobi, start, end)\n",
    "weather_df = ts.fetch()\n",
    "\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25f30906",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'NaN' from 'numpy' (c:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\numpy\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mms\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m date\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Nairobi location\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\__init__.py:18\u001b[39m\n\u001b[32m     15\u001b[39m __version__ = \u001b[33m\"\u001b[39m\u001b[33m1.6.5\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Base\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtimeseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSeries\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Stations\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\interface\\timeseries.py:25\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmeteodata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MeteoData\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mTimeSeries\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mMeteoData\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[33;43;03m    TimeSeries class which provides features which are\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[33;43;03m    used across all time series classes\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[33;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The list of origin weather Stations\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\interface\\timeseries.py:196\u001b[39m, in \u001b[36mTimeSeries\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    193\u001b[39m         \u001b[38;5;28mself\u001b[39m.clear_cache()\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Import methods\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnormalize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m normalize\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterpolate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interpolate\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maggregate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m aggregate\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\series\\normalize.py:12\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mNormalize Data\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03mThe code is licensed under the MIT license.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcopy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m copy\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NaN\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytz\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'NaN' from 'numpy' (c:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\numpy\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import meteostat as ms\n",
    "from datetime import date\n",
    "\n",
    "# Nairobi location\n",
    "nairobi = ms.Point(-1.2921, 36.8219)\n",
    "\n",
    "# Find nearby stations\n",
    "stations = ms.Stations()\n",
    "stations = stations.nearby(nairobi.lat, nairobi.lon)\n",
    "stations = stations.fetch(5)\n",
    "\n",
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b9a1fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: meteostat 1.6.5\n",
      "Uninstalling meteostat-1.6.5:\n",
      "  Successfully uninstalled meteostat-1.6.5\n",
      "Collecting meteostat==1.6.5\n",
      "  Using cached meteostat-1.6.5-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pandas>=1.1 in c:\\users\\moringa school\\anaconda3\\envs\\learn-env\\lib\\site-packages (from meteostat==1.6.5) (2.3.2)\n",
      "Requirement already satisfied: pytz in c:\\users\\moringa school\\anaconda3\\envs\\learn-env\\lib\\site-packages (from meteostat==1.6.5) (2023.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\moringa school\\anaconda3\\envs\\learn-env\\lib\\site-packages (from meteostat==1.6.5) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\moringa school\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=1.1->meteostat==1.6.5) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\moringa school\\anaconda3\\envs\\learn-env\\lib\\site-packages (from pandas>=1.1->meteostat==1.6.5) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\moringa school\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas>=1.1->meteostat==1.6.5) (1.17.0)\n",
      "Using cached meteostat-1.6.5-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: meteostat\n",
      "Successfully installed meteostat-1.6.5\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y meteostat\n",
    "!pip install meteostat==1.6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0a16467",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'NaN' from 'numpy' (c:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\numpy\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point, Daily, Stations\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Nairobi coordinates\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\__init__.py:18\u001b[39m\n\u001b[32m     15\u001b[39m __version__ = \u001b[33m\"\u001b[39m\u001b[33m1.6.5\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Base\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtimeseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSeries\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Stations\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\interface\\timeseries.py:25\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmeteodata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MeteoData\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mTimeSeries\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mMeteoData\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[33;43;03m    TimeSeries class which provides features which are\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[33;43;03m    used across all time series classes\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[33;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The list of origin weather Stations\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\interface\\timeseries.py:196\u001b[39m, in \u001b[36mTimeSeries\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    193\u001b[39m         \u001b[38;5;28mself\u001b[39m.clear_cache()\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Import methods\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnormalize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m normalize\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterpolate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interpolate\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeteostat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maggregate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m aggregate\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\meteostat\\series\\normalize.py:12\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mNormalize Data\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03mThe code is licensed under the MIT license.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcopy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m copy\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NaN\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytz\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'NaN' from 'numpy' (c:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\numpy\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from meteostat import Point, Daily, Stations\n",
    "from datetime import datetime\n",
    "\n",
    "# Nairobi coordinates\n",
    "nairobi = Point(-1.2921, 36.8219)\n",
    "\n",
    "# Find nearest station\n",
    "stations = Stations()\n",
    "stations = stations.nearby(nairobi.lat, nairobi.lon)\n",
    "station = stations.fetch(1)\n",
    "\n",
    "station_id = station.index[0]\n",
    "print(\"Using station:\", station_id)\n",
    "\n",
    "start = datetime(2007, 1, 1)\n",
    "end   = datetime(2008, 12, 31)\n",
    "\n",
    "data = Daily(station_id, start, end)\n",
    "weather_df = data.fetch()\n",
    "\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54236089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "883e8c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wspd_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>24.7</td>\n",
       "      <td>13.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-02</td>\n",
       "      <td>23.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-03</td>\n",
       "      <td>22.6</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-04</td>\n",
       "      <td>21.5</td>\n",
       "      <td>14.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>23.3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  tmax  tmin  prcp  wspd_max\n",
       "0 2007-01-01  24.7  13.1   1.0      17.6\n",
       "1 2007-01-02  23.2  13.7   0.1      17.4\n",
       "2 2007-01-03  22.6  14.8   0.9      20.0\n",
       "3 2007-01-04  21.5  14.9   2.3      21.4\n",
       "4 2007-01-05  23.3  12.9   0.0      18.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "lat, lon = -1.2921, 36.8219  # Nairobi\n",
    "start, end = \"2007-01-01\", \"2008-12-31\"\n",
    "\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "params = {\n",
    "    \"latitude\": lat,\n",
    "    \"longitude\": lon,\n",
    "    \"start_date\": start,\n",
    "    \"end_date\": end,\n",
    "    \"daily\": \"temperature_2m_max,temperature_2m_min,precipitation_sum,windspeed_10m_max\",\n",
    "    \"timezone\": \"Africa/Nairobi\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "weather_df = pd.DataFrame({\n",
    "    \"date\": data[\"daily\"][\"time\"],\n",
    "    \"tmax\": data[\"daily\"][\"temperature_2m_max\"],\n",
    "    \"tmin\": data[\"daily\"][\"temperature_2m_min\"],\n",
    "    \"prcp\": data[\"daily\"][\"precipitation_sum\"],\n",
    "    \"wspd_max\": data[\"daily\"][\"windspeed_10m_max\"]\n",
    "})\n",
    "\n",
    "weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"])\n",
    "\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ee9eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.to_csv(\"nairobi_weather_2007_2008.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58a716d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wspd_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>24.7</td>\n",
       "      <td>13.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-02</td>\n",
       "      <td>23.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-03</td>\n",
       "      <td>22.6</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-04</td>\n",
       "      <td>21.5</td>\n",
       "      <td>14.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>23.3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-01-06</td>\n",
       "      <td>24.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007-01-07</td>\n",
       "      <td>25.4</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007-01-08</td>\n",
       "      <td>26.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2007-01-09</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2007-01-10</td>\n",
       "      <td>24.7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2007-01-11</td>\n",
       "      <td>24.9</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2007-01-12</td>\n",
       "      <td>25.1</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2007-01-13</td>\n",
       "      <td>23.9</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2007-01-14</td>\n",
       "      <td>23.4</td>\n",
       "      <td>15.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2007-01-15</td>\n",
       "      <td>23.5</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2007-01-16</td>\n",
       "      <td>23.2</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2007-01-17</td>\n",
       "      <td>25.5</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2007-01-18</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2007-01-19</td>\n",
       "      <td>23.6</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>16.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2007-01-20</td>\n",
       "      <td>23.8</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  tmax  tmin  prcp  wspd_max\n",
       "0   2007-01-01  24.7  13.1   1.0      17.6\n",
       "1   2007-01-02  23.2  13.7   0.1      17.4\n",
       "2   2007-01-03  22.6  14.8   0.9      20.0\n",
       "3   2007-01-04  21.5  14.9   2.3      21.4\n",
       "4   2007-01-05  23.3  12.9   0.0      18.5\n",
       "5   2007-01-06  24.5  13.0   0.3      15.7\n",
       "6   2007-01-07  25.4  12.8   0.0      12.0\n",
       "7   2007-01-08  26.4  13.7   0.0      10.7\n",
       "8   2007-01-09  26.0  13.3   0.0      15.0\n",
       "9   2007-01-10  24.7  13.3   0.0      16.9\n",
       "10  2007-01-11  24.9  13.5   0.0      17.8\n",
       "11  2007-01-12  25.1  13.2   0.0      12.2\n",
       "12  2007-01-13  23.9  14.7   1.9      13.6\n",
       "13  2007-01-14  23.4  15.6   2.6      16.1\n",
       "14  2007-01-15  23.5  15.6   1.3      15.8\n",
       "15  2007-01-16  23.2  14.9   0.9      11.8\n",
       "16  2007-01-17  25.5  14.7   0.7      16.9\n",
       "17  2007-01-18  24.0  14.9   1.6      19.3\n",
       "18  2007-01-19  23.6  15.5   1.1      16.3\n",
       "19  2007-01-20  23.8  14.8   0.0      14.8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"nairobi_weather_2007_2008.csv\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27fcd936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c:\\Users\\Moringa' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca788811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c:\\Users\\Moringa' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pdfplumber beautifulsoup4 python-dateutil requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99e91800",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdfplumber'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfplumber\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pdfplumber'"
     ]
    }
   ],
   "source": [
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b484b19",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'kplc_pdfs/YOUR_FILE_NAME.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Put the path to ONE downloaded KPLC PDF here\u001b[39;00m\n\u001b[32m      4\u001b[39m pdf_path = \u001b[33m\"\u001b[39m\u001b[33mkplc_pdfs/YOUR_FILE_NAME.pdf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m reader = \u001b[43mPdfReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m reader.pages:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\PyPDF2\\_reader.py:317\u001b[39m, in \u001b[36mPdfReader.__init__\u001b[39m\u001b[34m(self, stream, strict, password)\u001b[39m\n\u001b[32m    311\u001b[39m     logger_warning(\n\u001b[32m    312\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPdfReader stream/file object is not in binary mode. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    313\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt may not be read correctly.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    314\u001b[39m         \u001b[34m__name__\u001b[39m,\n\u001b[32m    315\u001b[39m     )\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream, (\u001b[38;5;28mstr\u001b[39m, Path)):\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[32m    318\u001b[39m         stream = BytesIO(fh.read())\n\u001b[32m    319\u001b[39m \u001b[38;5;28mself\u001b[39m.read(stream)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'kplc_pdfs/YOUR_FILE_NAME.pdf'"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Put the path to ONE downloaded KPLC PDF here\n",
    "pdf_path = \"kplc_pdfs/YOUR_FILE_NAME.pdf\"\n",
    "\n",
    "reader = PdfReader(pdf_path)\n",
    "\n",
    "text = \"\"\n",
    "for page in reader.pages:\n",
    "    extracted = page.extract_text()\n",
    "    if extracted:\n",
    "        text += extracted + \"\\n\"\n",
    "\n",
    "print(text[:1500])  # Print first 1500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5790adc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:\n",
      "c:\\Users\\Moringa School\\Desktop\\Data\n",
      "\n",
      "Files in this directory:\n",
      "['household_power_consumption.txt', 'index.ipynb', 'kplc_daily_schedule.csv', 'kplc_notice.pdf', 'kplc_planned_outages.csv', 'nairobi_weather_2007_2008.csv', 'power_raw_cleaned.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Current working directory:\")\n",
    "print(os.getcwd())\n",
    "\n",
    "print(\"\\nFiles in this directory:\")\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e561a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: kplc_notice.pdf\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "pdf_url = \"https://www.kplc.co.ke/storage/01KF0S2D9KT9RD13M0NJX35AG3.pdf\"\n",
    "filename = \"kplc_notice.pdf\"\n",
    "\n",
    "response = requests.get(pdf_url)\n",
    "\n",
    "with open(filename, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "print(\"Downloaded:\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35cbdc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['household_power_consumption.txt', 'index.ipynb', 'kplc_daily_schedule.csv', 'kplc_notice.pdf', 'kplc_planned_outages.csv', 'nairobi_weather_2007_2008.csv', 'power_raw_cleaned.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9490af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "Interruption of  \n",
      "Electricity Supply  \n",
      "Notice is hereby given under R ule 27 of the Electric Power Rules  \n",
      "That the electricity supply will be interrupted as here under:  \n",
      "(It is necessary to interrupt supply periodically in order to facilitate \n",
      "maintenance and upgrade of power lines to the network; to connect new \n",
      "customers or to replace power lines during road construction, etc.)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "NAIROBI REGION  \n",
      "PARTS OF NAIROBI COUNTY  \n",
      "AREA: PART OF LUNGA LUNGA ROAD AND LIKONI ROAD  \n",
      "DATE: Sunday 18.01.2026                                     TIME: 8.00 A.M.  5.00 P.M.  \n",
      "House of Manji, Wheatabix, Part of Likoni Rd, Ashut Head Office, Lokitaung \n",
      "Road, Smithkline Beacham, Lunga Lunga Square, Mareba Enterprises, Whole of \n",
      "Rangwe Rd, Clesoi Rd, Sasio Rd Patco Industries, Nairobi Plastics, Cosmos, \n",
      "Sansora Group & adjacent custom ers. \n",
      " \n",
      "AREA: WHOLE OF GARAGE ROAD  \n",
      "DATE: Tuesday 20.01.2026                                   TIME: 9.00 A.M  5.00 P.M.  \n",
      "Whole of Garage Rd & adjacent customers.  \n",
      " \n",
      "AREA: WHOLE OF MPWEKE LANE  \n",
      "DATE: Thursday 22.01.2026                        TIME: 9.00 A.M.  5.00 P.M.  \n",
      "Total South B, Part of Kapiti Rd, Whole of Mpweke Lane & adjacent customers.  \n",
      " \n",
      "PARTS OF KAJIADO COUNTY  \n",
      "AREA: ONGATA RONGAI  \n",
      "DATE: Wednesday 21.01.2026                                  TIME: 9.00  A.M.  5.00 P.M. \n",
      "Whole of Gataka Rd from Masai Mall, Kisumu Ndogo Beacon of Hope, Nakeel \n",
      "Schools. Oloolaiser Water Offices, Wanugu/Melonye Rd, Barizi, Kwa \n",
      "Mwai,Gataka Shopping Ce\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "reader = PdfReader(\"kplc_notice.pdf\")\n",
    "\n",
    "text = \"\"\n",
    "for page in reader.pages:\n",
    "    extracted = page.extract_text()\n",
    "    if extracted:\n",
    "        text += extracted + \"\\n\"\n",
    "\n",
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44d45c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows parsed: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: kplc_planned_outages.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from dateutil import parser as dateparser\n",
    "\n",
    "# -------- Patterns (edit if your notice format differs) --------\n",
    "# Example date lines: \"WEDNESDAY, 27TH JANUARY 2026\"\n",
    "DATE_RE = re.compile(\n",
    "    r\"\\b(MONDAY|TUESDAY|WEDNESDAY|THURSDAY|FRIDAY|SATURDAY|SUNDAY)\\b\\s*,?\\s*\"\n",
    "    r\"(\\d{1,2})(?:ST|ND|RD|TH)?\\s+([A-Z]+)\\s+(\\d{4})\\b\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# Example time lines: \"9.00 A.M.  5.00 P.M.\" or \"8:00AM-4:00PM\"\n",
    "TIME_RE = re.compile(\n",
    "    r\"(\\d{1,2}[:.]\\d{2}\\s*(?:A\\.?M\\.?|P\\.?M\\.?|AM|PM)?)\\s*[-]\\s*\"\n",
    "    r\"(\\d{1,2}[:.]\\d{2}\\s*(?:A\\.?M\\.?|P\\.?M\\.?|AM|PM)?)\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# County header lines: \"NAIROBI COUNTY\"\n",
    "COUNTY_RE = re.compile(r\"^[A-Z][A-Z\\s&/-]{2,}\\s+COUNTY$\", re.IGNORECASE)\n",
    "\n",
    "\n",
    "def normalize_text(t: str) -> str:\n",
    "    t = t.replace(\"\\u00a0\", \" \")\n",
    "    t = re.sub(r\"[ \\t]+\", \" \", t)\n",
    "    t = re.sub(r\"\\n{2,}\", \"\\n\", t)\n",
    "    return t.strip()\n",
    "\n",
    "\n",
    "def to_iso_date(line: str):\n",
    "    \"\"\"Convert detected date header line into YYYY-MM-DD.\"\"\"\n",
    "    m = DATE_RE.search(line)\n",
    "    if not m:\n",
    "        return None\n",
    "    day = m.group(2)\n",
    "    month = m.group(3)\n",
    "    year = m.group(4)\n",
    "    dt = dateparser.parse(f\"{day} {month} {year}\", dayfirst=True)\n",
    "    return dt.date().isoformat()\n",
    "\n",
    "\n",
    "def normalize_time(t: str) -> str:\n",
    "    \"\"\"Normalize times like '9.00 A.M.' -> '09:00' (24h).\"\"\"\n",
    "    t = t.upper().replace(\"A.M.\", \"AM\").replace(\"P.M.\", \"PM\").replace(\"A.M\", \"AM\").replace(\"P.M\", \"PM\")\n",
    "    t = t.replace(\" \", \"\")\n",
    "    t = re.sub(r\"^(\\d{1,2})\\.(\\d{2})(AM|PM)?$\", r\"\\1:\\2\\3\", t)  # 9.00AM -> 9:00AM\n",
    "    dt = dateparser.parse(t)\n",
    "    return dt.strftime(\"%H:%M\")\n",
    "\n",
    "\n",
    "def parse_kplc_text(text: str) -> pd.DataFrame:\n",
    "    text = normalize_text(text)\n",
    "    lines = [ln.strip() for ln in text.split(\"\\n\") if ln.strip()]\n",
    "\n",
    "    rows = []\n",
    "    current_date = None\n",
    "    current_county = None\n",
    "    current_time = None\n",
    "    area_buffer = []\n",
    "\n",
    "    def flush():\n",
    "        nonlocal area_buffer, rows, current_date, current_county, current_time\n",
    "        if current_date and current_time and area_buffer:\n",
    "            rows.append({\n",
    "                \"date\": current_date,\n",
    "                \"start_time\": normalize_time(current_time[0]),\n",
    "                \"end_time\": normalize_time(current_time[1]),\n",
    "                \"county_or_region\": current_county,\n",
    "                \"areas\": \" \".join(area_buffer).strip()\n",
    "            })\n",
    "        area_buffer = []\n",
    "\n",
    "    for ln in lines:\n",
    "        # Date header\n",
    "        d = to_iso_date(ln)\n",
    "        if d:\n",
    "            flush()\n",
    "            current_date = d\n",
    "            current_county = None\n",
    "            current_time = None\n",
    "            continue\n",
    "\n",
    "        # County header\n",
    "        if COUNTY_RE.match(ln):\n",
    "            flush()\n",
    "            current_county = ln.title()\n",
    "            current_time = None\n",
    "            continue\n",
    "\n",
    "        # Time range\n",
    "        tm = TIME_RE.search(ln)\n",
    "        if tm:\n",
    "            flush()\n",
    "            current_time = (tm.group(1), tm.group(2))\n",
    "\n",
    "            # Areas sometimes begin on same line after the time range\n",
    "            rest = TIME_RE.sub(\"\", ln).strip(\" :-\")\n",
    "            if rest:\n",
    "                area_buffer.append(rest)\n",
    "            continue\n",
    "\n",
    "        # Area lines (only if inside a time block)\n",
    "        if current_date and current_time:\n",
    "            area_buffer.append(ln)\n",
    "\n",
    "    flush()\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# ---- Run parser ----\n",
    "kplc_df = parse_kplc_text(text)\n",
    "\n",
    "# Quick check\n",
    "print(\"Rows parsed:\", len(kplc_df))\n",
    "display(kplc_df.head(10))\n",
    "\n",
    "# Save to CSV\n",
    "kplc_df.to_csv(\"kplc_planned_outages.csv\", index=False)\n",
    "print(\"Saved: kplc_planned_outages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b009071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "RangeIndex(start=0, stop=0, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(kplc_df.shape)\n",
    "print(kplc_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c43411e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "Interruption of  \n",
      "Electricity Supply  \n",
      "Notice is hereby given under R ule 27 of the Electric Power Rules  \n",
      "That the electricity supply will be interrupted as here under:  \n",
      "(It is necessary to interrupt supply periodically in order to facilitate \n",
      "maintenance and upgrade of power lines to the network; to connect new \n",
      "customers or to replace power lines during road construction, etc.)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "NAIROBI REGION  \n",
      "PARTS OF NAIROBI COUNTY  \n",
      "AREA: PART OF LUNGA LUNGA ROAD AND LIKONI ROAD  \n",
      "DATE: Sunday 18.01.2026                                     TIME: 8.00 A.M.  5.00 P.M.  \n",
      "House of Manji, Wheatabix, Part of Likoni Rd, Ashut Head Office, Lokitaung \n",
      "Road, Smithkline Beacham, Lunga Lunga Square, Mareba Enterprises, Whole of \n",
      "Rangwe Rd, Clesoi Rd, Sasio Rd Patco Industries, Nairobi Plastics, Cosmos, \n",
      "Sansora Group & adjacent custom ers. \n",
      " \n",
      "AREA: WHOLE OF GARAGE ROAD  \n",
      "DATE: Tuesday 20.01.2026                                   TIME: 9.00 A.M  5.00 P.M.  \n",
      "Whole of Garage Rd & adjacent customers.  \n",
      " \n",
      "AREA: WHOLE OF MPWEKE LANE  \n",
      "DATE: Thursday 22.01.2026                        TIME: 9.00 A.M.  5.00 P.M.  \n",
      "Total South B, Part of Kapiti Rd, Whole of Mpweke Lane & adjacent customers.  \n",
      " \n",
      "PARTS OF KAJIADO COUNTY  \n",
      "AREA: ONGATA RONGAI  \n",
      "DATE: Wednesday 21.01.2026                                  TIME: 9.00  A.M.  5.00 P.M. \n",
      "Whole of Gataka Rd from Masai Mall, Kisumu Ndogo Beacon of Hope, Nakeel \n",
      "Schools. Oloolaiser Water Offices, Wanugu/Melonye Rd, Barizi, Kwa \n",
      "Mwai,Gataka Shopping Center Including Oloolua  Forest, Mayor Rd, Hass Petrol \n",
      "Station  & adjacent customers.  \n",
      "  \n",
      " \n",
      "CENTRAL RIFT REGION  \n",
      "PARTS OF KERICHO COUNTY  \n",
      "AREA: PARTS OF KURESOI NORTH  \n",
      "DATE: Wednesday 21.01.2026                               TIME: 9.00 A.M.  5.00 P.M.  \n",
      "Murundu Mkt, Kibaraa Mkt, Kipkoris Mkt, Kipkewa Mkt, Kongoi Mkt, Mawingu \n",
      "Mkt, Koraboriet Mkt & adjacent customers.\n",
      "  \n",
      " \n",
      " \n",
      "PARTS OF NYANDADRUA COUNTY  \n",
      "AREA: PARTS OF ENGINEER, NDUNYU NJERU, NJAMBINI  \n",
      "DATE: Thursday 22.01.2026              \n"
     ]
    }
   ],
   "source": [
    "print(text[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "054aeaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (0, 0)\n",
      "RangeIndex(start=0, stop=0, step=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: kplc_planned_outages.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Regex patterns matching YOUR notice style ---\n",
    "AREA_RE = re.compile(r\"^AREA:\\s*(.+)$\", re.IGNORECASE)\n",
    "# Example: \"DATE: Sunday 18.01.2026\"\n",
    "DATE_RE = re.compile(r\"DATE:\\s*(?:[A-Za-z]+\\s*)?(\\d{1,2}\\.\\d{1,2}\\.\\d{4})\", re.IGNORECASE)\n",
    "# Example: \"TIME: 8.00 A.M.  5.00 P.M.\"\n",
    "TIME_RE = re.compile(\n",
    "    r\"TIME:\\s*(\\d{1,2}[.:]\\d{2}\\s*(?:A\\.?M\\.?|P\\.?M\\.?)?)\\s*[-]\\s*(\\d{1,2}[.:]\\d{2}\\s*(?:A\\.?M\\.?|P\\.?M\\.?)?)\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "REGION_RE = re.compile(r\".+\\s+REGION$\", re.IGNORECASE)\n",
    "PARTS_COUNTY_RE = re.compile(r\"PARTS OF\\s+(.+?)\\s+COUNTY\", re.IGNORECASE)\n",
    "\n",
    "def normalize_time(t: str) -> str:\n",
    "    \"\"\"Convert '8.00 A.M.' or '9.00 A.M' to '08:00' 24-hour time.\"\"\"\n",
    "    t = t.upper().replace(\"A.M.\", \"AM\").replace(\"P.M.\", \"PM\").replace(\"A.M\", \"AM\").replace(\"P.M\", \"PM\")\n",
    "    t = t.replace(\" \", \"\")\n",
    "    t = t.replace(\".\", \":\")  # 8.00AM -> 8:00AM\n",
    "    # Ensure HH:MM\n",
    "    # Sometimes replacement makes 8:00:AM; fix quickly\n",
    "    t = t.replace(\":AM\", \"AM\").replace(\":PM\", \"PM\")\n",
    "    dt = datetime.strptime(t, \"%I:%M%p\")\n",
    "    return dt.strftime(\"%H:%M\")\n",
    "\n",
    "def normalize_date(d: str) -> str:\n",
    "    \"\"\"Convert '18.01.2026' to '2026-01-18'.\"\"\"\n",
    "    return datetime.strptime(d, \"%d.%m.%Y\").date().isoformat()\n",
    "\n",
    "def parse_kplc_notice(text: str) -> pd.DataFrame:\n",
    "    # Clean whitespace\n",
    "    text = text.replace(\"\\u00a0\", \" \")\n",
    "    lines = [ln.strip() for ln in text.split(\"\\n\") if ln.strip()]\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    current_region = None\n",
    "    current_county = None\n",
    "\n",
    "    current_area = None\n",
    "    current_date = None\n",
    "    current_time = None\n",
    "    customers_buffer = []\n",
    "\n",
    "    def flush():\n",
    "        nonlocal current_area, current_date, current_time, customers_buffer, rows\n",
    "        if current_area and current_date and current_time:\n",
    "            rows.append({\n",
    "                \"region\": current_region,\n",
    "                \"county\": current_county,\n",
    "                \"area\": current_area,\n",
    "                \"date\": current_date,\n",
    "                \"start_time\": current_time[0],\n",
    "                \"end_time\": current_time[1],\n",
    "                \"affected_customers\": \" \".join(customers_buffer).strip()\n",
    "            })\n",
    "        current_area = None\n",
    "        current_date = None\n",
    "        current_time = None\n",
    "        customers_buffer = []\n",
    "\n",
    "    for ln in lines:\n",
    "        # Region header e.g. \"NAIROBI REGION\"\n",
    "        if REGION_RE.match(ln):\n",
    "            flush()\n",
    "            current_region = ln.title()\n",
    "            continue\n",
    "\n",
    "        # County header e.g. \"PARTS OF NAIROBI COUNTY\"\n",
    "        m_county = PARTS_COUNTY_RE.search(ln)\n",
    "        if m_county:\n",
    "            flush()\n",
    "            current_county = m_county.group(1).title()\n",
    "            continue\n",
    "\n",
    "        # AREA line\n",
    "        m_area = AREA_RE.match(ln)\n",
    "        if m_area:\n",
    "            flush()\n",
    "            current_area = m_area.group(1).strip().title()\n",
    "            continue\n",
    "\n",
    "        # DATE line\n",
    "        m_date = DATE_RE.search(ln)\n",
    "        if m_date:\n",
    "            current_date = normalize_date(m_date.group(1))\n",
    "            continue\n",
    "\n",
    "        # TIME line\n",
    "        m_time = TIME_RE.search(ln)\n",
    "        if m_time:\n",
    "            start_t = normalize_time(m_time.group(1))\n",
    "            end_t = normalize_time(m_time.group(2))\n",
    "            current_time = (start_t, end_t)\n",
    "            continue\n",
    "\n",
    "        # Otherwise: customer/locations details (only after area started)\n",
    "        if current_area:\n",
    "            customers_buffer.append(ln)\n",
    "\n",
    "    flush()\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "# ---- Run it ----\n",
    "kplc_df = parse_kplc_notice(text)\n",
    "\n",
    "print(\"Shape:\", kplc_df.shape)\n",
    "print(kplc_df.columns)\n",
    "display(kplc_df.head(10))\n",
    "\n",
    "# Save\n",
    "kplc_df.to_csv(\"kplc_planned_outages.csv\", index=False)\n",
    "print(\"Saved: kplc_planned_outages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8834c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AREA: PART OF LUNGA LUNGA ROAD AND LIKONI ROAD\n",
      "DATE: Sunday 18.01.2026                                     TIME: 8.00 A.M.  5.00 P.M.\n",
      "AREA: WHOLE OF GARAGE ROAD\n",
      "DATE: Tuesday 20.01.2026                                   TIME: 9.00 A.M  5.00 P.M.\n",
      "AREA: WHOLE OF MPWEKE LANE\n",
      "DATE: Thursday 22.01.2026                        TIME: 9.00 A.M.  5.00 P.M.\n",
      "AREA: ONGATA RONGAI\n",
      "DATE: Wednesday 21.01.2026                                  TIME: 9.00  A.M.  5.00 P.M.\n",
      "AREA: PARTS OF KURESOI NORTH\n",
      "DATE: Wednesday 21.01.2026                               TIME: 9.00 A.M.  5.00 P.M.\n",
      "AREA: PARTS OF ENGINEER, NDUNYU NJERU, NJAMBINI\n",
      "DATE: Thursday 22.01.2026                                     TIME: 9.00 A.M . - 4.30 P.M.\n",
      "AREA: PARTS OF MAWINGU, MACHINNERY, MIHARATI\n",
      "DATE:  Friday 23.01.2026                                          TIME: 9.00 A.M. - 4.30 P.M.\n",
      "AREA: WEST INDIES ESTATE\n",
      "DATE: Sunday 18.01.2026                                      TIME : 9.00 A.M.  3.00 P.M.\n",
      "AREA: KAPCHUMBA, LOWER KIPLOMBE\n",
      "DATE:  Tuesday 20.01.2026                                   TIME : 9.00 A.M.  5.00 P.M.\n",
      "AREA: KIPKENYO SIMAT\n",
      "DATE: Thursday 22.01.2026                    TIME : 9.00 A.M  4.00 P.M.\n",
      "DATE:  Thursday 22.01.2026                    TIME : 9.00 A.M  5.00 P.M.\n",
      "AREA: CHIGA\n",
      "DATE: Tuesday 20.01.2026                                   TIME: 8 .30 A .M. - 5.00 P.M.\n",
      "AREA: NAMULUNGU\n",
      "DATE : Sunday  18.01.2026                                      TIME: 9 .00 A .M - 5.00 P.M.\n",
      "AREA: AMALEMBA.\n",
      "DATE: Tuesday 20.01.2026                                    TIME: 9 .00 A .M. - 5.00 P.M.\n",
      "AREA: MURUGURU, KIAMUIRU, GITHIRU\n",
      "DATE: Monday 19.01.2026                                     TIME: 9.00 A.M .  5.00 P .M.\n",
      "AREA: IHURURU,  MATHARI HOSPITAL, NJOGUINI\n",
      "DATE: Monday 19.01.2026                                     TIME: 9.00 A.M .  5.00 P .M.\n",
      "AREA: KIHOYA, WANJERERE, GACHARAGE\n",
      "DATE: Tuesday 20.01.2026                                    TIME: 9.00 A.M .  5.00 P .M.\n",
      "AREA: SOLIO RANCH, SOLIO WATER PUMP\n",
      "DATE: Thursday 22.01.2026                                   TIME: 9.00 A.M .  5.00 P .M.\n",
      "AREA: KAHIGAINI, KIANDU, ITHENGURI\n",
      "DATE: Friday  23.01.2026                                        TIME: 9.00 A.M .  5.00 P .M.\n",
      "AREA: KIGANJO POLICE COLLEGE, KIRICHU\n",
      "DATE: Saturday 24.01.2026                                    TIME: 9.00 A.M .  5.00 P .M.\n",
      "AREAS: MAKUTANO, MUTITHI, MWEA\n",
      "DATE: Thursday 22.01.2026                                   TIME: 9.00 A.M .  5.00 P.M .\n",
      "AREAS: RUKURIRI, KYENI HOSPITAL, MUFU\n",
      "DATE: Monday 19.01.2026                                     TIME: 8.30 A.M .  5.00 P.M .\n"
     ]
    }
   ],
   "source": [
    "# Show lines that mention AREA / DATE / TIME (so we match the real format)\n",
    "lines = [ln.strip() for ln in text.split(\"\\n\") if ln.strip()]\n",
    "\n",
    "for ln in lines:\n",
    "    if \"AREA\" in ln.upper() or \"DATE\" in ln.upper() or \"TIME\" in ln.upper():\n",
    "        print(ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8480c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (13, 5)\n",
      "Columns: ['area', 'date', 'start_time', 'end_time', 'affected_customers']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>date</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>affected_customers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Part Of Lunga Lunga Road And Likoni Road</td>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>08:00</td>\n",
       "      <td>17:00</td>\n",
       "      <td>House of Manji, Wheatabix, Part of Likoni Rd, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whole Of Garage Road</td>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>09:00</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Whole of Garage Rd &amp; adjacent customers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whole Of Mpweke Lane</td>\n",
       "      <td>2026-01-22</td>\n",
       "      <td>09:00</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Total South B, Part of Kapiti Rd, Whole of Mpw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ongata Rongai</td>\n",
       "      <td>2026-01-21</td>\n",
       "      <td>09:00</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Whole of Gataka Rd from Masai Mall, Kisumu Ndo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parts Of Kuresoi North</td>\n",
       "      <td>2026-01-21</td>\n",
       "      <td>09:00</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Murundu Mkt, Kibaraa Mkt, Kipkoris Mkt, Kipkew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Parts Of Mawingu, Machinnery, Miharati</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>09:00</td>\n",
       "      <td>16:30</td>\n",
       "      <td>Whole of Mumui, Mawingu, Matopeni, Gathiriga, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>West Indies Estate</td>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>09:00</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Gulab Lochab Academy, Pauls Bakery, Part of W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kapchumba, Lower Kiplombe</td>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>09:00</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Kapchumba, Baharini Police Post, Lower Kiplomb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kipkenyo Simat</td>\n",
       "      <td>2026-01-22</td>\n",
       "      <td>09:00</td>\n",
       "      <td>16:00</td>\n",
       "      <td>Kipkenyo Primary, Eldowas Sewage, Liberty Sch,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kipkenyo Simat</td>\n",
       "      <td>2026-01-22</td>\n",
       "      <td>09:00</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Kapkagaron, Centre Kwanza , Kilibwoni, Tulon Q...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       area        date start_time end_time  \\\n",
       "0  Part Of Lunga Lunga Road And Likoni Road  2026-01-18      08:00    17:00   \n",
       "1                      Whole Of Garage Road  2026-01-20      09:00    17:00   \n",
       "2                      Whole Of Mpweke Lane  2026-01-22      09:00    17:00   \n",
       "3                             Ongata Rongai  2026-01-21      09:00    17:00   \n",
       "4                    Parts Of Kuresoi North  2026-01-21      09:00    17:00   \n",
       "5    Parts Of Mawingu, Machinnery, Miharati  2026-01-23      09:00    16:30   \n",
       "6                        West Indies Estate  2026-01-18      09:00    15:00   \n",
       "7                 Kapchumba, Lower Kiplombe  2026-01-20      09:00    17:00   \n",
       "8                            Kipkenyo Simat  2026-01-22      09:00    16:00   \n",
       "9                            Kipkenyo Simat  2026-01-22      09:00    17:00   \n",
       "\n",
       "                                  affected_customers  \n",
       "0  House of Manji, Wheatabix, Part of Likoni Rd, ...  \n",
       "1           Whole of Garage Rd & adjacent customers.  \n",
       "2  Total South B, Part of Kapiti Rd, Whole of Mpw...  \n",
       "3  Whole of Gataka Rd from Masai Mall, Kisumu Ndo...  \n",
       "4  Murundu Mkt, Kibaraa Mkt, Kipkoris Mkt, Kipkew...  \n",
       "5  Whole of Mumui, Mawingu, Matopeni, Gathiriga, ...  \n",
       "6  Gulab Lochab Academy, Pauls Bakery, Part of W...  \n",
       "7  Kapchumba, Baharini Police Post, Lower Kiplomb...  \n",
       "8  Kipkenyo Primary, Eldowas Sewage, Liberty Sch,...  \n",
       "9  Kapkagaron, Centre Kwanza , Kilibwoni, Tulon Q...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: kplc_planned_outages.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_spaces(s: str) -> str:\n",
    "    s = s.replace(\"\\u00a0\", \" \")\n",
    "    s = s.replace(\"\", \"-\").replace(\"\", \"-\").replace(\"\", \"-\")\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def normalize_ampm(s: str) -> str:\n",
    "    # Turn \"A .M.\" / \"A .M\" / \"A.M.\" etc into AM, same for PM\n",
    "    s = s.upper()\n",
    "    s = re.sub(r\"A\\s*\\.?\\s*M\\.?\", \"AM\", s)\n",
    "    s = re.sub(r\"P\\s*\\.?\\s*M\\.?\", \"PM\", s)\n",
    "    return s\n",
    "\n",
    "def parse_date(d: str) -> str:\n",
    "    # d like 18.01.2026\n",
    "    return datetime.strptime(d, \"%d.%m.%Y\").date().isoformat()\n",
    "\n",
    "def parse_time(h: str, m: str, ampm: str) -> str:\n",
    "    # h,m like \"8\",\"00\" and ampm like \"AM\"/\"PM\"\n",
    "    t = f\"{int(h)}:{m}{ampm}\"\n",
    "    dt = datetime.strptime(t, \"%I:%M%p\")\n",
    "    return dt.strftime(\"%H:%M\")\n",
    "\n",
    "AREA_LINE_RE = re.compile(r\"^AREAS?\\s*:\\s*(.+)$\", re.IGNORECASE)\n",
    "\n",
    "# Matches:\n",
    "# DATE: Sunday 18.01.2026 TIME: 8.00 A.M.  5.00 P.M.\n",
    "# DATE : Sunday  18.01.2026 TIME: 9 .00 A .M - 5.00 P.M.\n",
    "DATE_TIME_RE = re.compile(\n",
    "    r\"DATE\\s*:\\s*(?:[A-Za-z]+\\s*)?(\\d{1,2}\\.\\d{1,2}\\.\\d{4}).*?\"\n",
    "    r\"TIME\\s*:\\s*\"\n",
    "    r\"(\\d{1,2})\\s*[.:]\\s*(\\d{2})\\s*([AP]\\s*\\.?\\s*M\\.?)\\s*-\\s*\"\n",
    "    r\"(\\d{1,2})\\s*[.:]\\s*(\\d{2})\\s*([AP]\\s*\\.?\\s*M\\.?)\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def parse_kplc_text(text: str) -> pd.DataFrame:\n",
    "    lines = [ln.strip() for ln in text.split(\"\\n\") if ln.strip()]\n",
    "\n",
    "    rows = []\n",
    "    current_area = None\n",
    "    current_date = None\n",
    "    current_start = None\n",
    "    current_end = None\n",
    "    buf = []\n",
    "\n",
    "    def flush():\n",
    "        nonlocal current_area, current_date, current_start, current_end, buf, rows\n",
    "        if current_date and current_start and current_end:\n",
    "            rows.append({\n",
    "                \"area\": current_area if current_area else \"UNKNOWN\",\n",
    "                \"date\": current_date,\n",
    "                \"start_time\": current_start,\n",
    "                \"end_time\": current_end,\n",
    "                \"affected_customers\": \" \".join(buf).strip()\n",
    "            })\n",
    "        # reset event buffer (but keep area until next area line)\n",
    "        current_date = None\n",
    "        current_start = None\n",
    "        current_end = None\n",
    "        buf = []\n",
    "\n",
    "    for raw in lines:\n",
    "        ln = clean_spaces(raw)\n",
    "\n",
    "        # 1) AREA/AREAS line starts a new block -> flush previous event\n",
    "        m_area = AREA_LINE_RE.match(ln)\n",
    "        if m_area:\n",
    "            flush()\n",
    "            current_area = m_area.group(1).strip().title()\n",
    "            continue\n",
    "\n",
    "        # 2) DATE+TIME line defines the event timing\n",
    "        m_dt = DATE_TIME_RE.search(normalize_ampm(ln))\n",
    "        if m_dt:\n",
    "            # If we see a new DATE/TIME before flushing, flush previous\n",
    "            flush()\n",
    "\n",
    "            d = m_dt.group(1)\n",
    "            sh, sm, sampm = m_dt.group(2), m_dt.group(3), normalize_ampm(m_dt.group(4))\n",
    "            eh, em, eampm = m_dt.group(5), m_dt.group(6), normalize_ampm(m_dt.group(7))\n",
    "\n",
    "            current_date = parse_date(d)\n",
    "            current_start = parse_time(sh, sm, sampm)\n",
    "            current_end = parse_time(eh, em, eampm)\n",
    "            continue\n",
    "\n",
    "        # 3) Everything else is customer/location text (only if we're inside an event)\n",
    "        if current_date and current_start and current_end:\n",
    "            buf.append(ln)\n",
    "\n",
    "    flush()\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "kplc_df = parse_kplc_text(text)\n",
    "\n",
    "print(\"Shape:\", kplc_df.shape)\n",
    "print(\"Columns:\", list(kplc_df.columns))\n",
    "display(kplc_df.head(10))\n",
    "\n",
    "kplc_df.to_csv(\"kplc_planned_outages.csv\", index=False)\n",
    "print(\"Saved: kplc_planned_outages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19ff4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "kplc_df[\"date\"] = pd.to_datetime(kplc_df[\"date\"])\n",
    "kplc_df.to_csv(\"kplc_planned_outages.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d75f3ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>scheduled_outage_today</th>\n",
       "      <th>n_scheduled_events</th>\n",
       "      <th>total_scheduled_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-21</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  scheduled_outage_today  n_scheduled_events  \\\n",
       "0 2026-01-18                       1                   3   \n",
       "1 2026-01-20                       1                   4   \n",
       "2 2026-01-21                       1                   2   \n",
       "3 2026-01-22                       1                   3   \n",
       "4 2026-01-23                       1                   1   \n",
       "\n",
       "   total_scheduled_minutes  \n",
       "0                   1380.0  \n",
       "1                   1950.0  \n",
       "2                    960.0  \n",
       "3                   1380.0  \n",
       "4                    450.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = kplc_df.copy()\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# Convert start/end times into timedeltas (minutes from midnight)\n",
    "df[\"start_dt\"] = pd.to_datetime(df[\"date\"].dt.date.astype(str) + \" \" + df[\"start_time\"])\n",
    "df[\"end_dt\"]   = pd.to_datetime(df[\"date\"].dt.date.astype(str) + \" \" + df[\"end_time\"])\n",
    "\n",
    "# Duration in minutes\n",
    "df[\"duration_minutes\"] = (df[\"end_dt\"] - df[\"start_dt\"]).dt.total_seconds() / 60\n",
    "\n",
    "daily_kplc = (\n",
    "    df.groupby(df[\"date\"].dt.date)\n",
    "      .agg(\n",
    "          scheduled_outage_today=(\"area\", lambda x: 1),\n",
    "          n_scheduled_events=(\"area\", \"count\"),\n",
    "          total_scheduled_minutes=(\"duration_minutes\", \"sum\")\n",
    "      )\n",
    "      .reset_index()\n",
    "      .rename(columns={\"index\": \"date\"})\n",
    ")\n",
    "\n",
    "daily_kplc[\"date\"] = pd.to_datetime(daily_kplc[\"date\"])\n",
    "\n",
    "daily_kplc.to_csv(\"kplc_daily_schedule.csv\", index=False)\n",
    "daily_kplc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e871fe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated. Combine the desired columns with pd.to_datetime after parsing instead.\n",
      "FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-12-16 17:24:00</td>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.84</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-12-16 17:25:00</td>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.63</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-12-16 17:26:00</td>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.29</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-12-16 17:27:00</td>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.74</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-12-16 17:28:00</td>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.68</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  Global_active_power  Global_reactive_power  Voltage  \\\n",
       "0 2006-12-16 17:24:00                4.216                  0.418   234.84   \n",
       "1 2006-12-16 17:25:00                5.360                  0.436   233.63   \n",
       "2 2006-12-16 17:26:00                5.374                  0.498   233.29   \n",
       "3 2006-12-16 17:27:00                5.388                  0.502   233.74   \n",
       "4 2006-12-16 17:28:00                3.666                  0.528   235.68   \n",
       "\n",
       "   Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
       "0              18.4             0.0             1.0            17.0  \n",
       "1              23.0             0.0             1.0            16.0  \n",
       "2              23.0             0.0             2.0            17.0  \n",
       "3              23.0             0.0             1.0            17.0  \n",
       "4              15.8             0.0             1.0            17.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "power_df = pd.read_csv(\n",
    "    \"household_power_consumption.txt\",\n",
    "    sep=\";\",\n",
    "    na_values=\"?\",\n",
    "    parse_dates={\"datetime\": [\"Date\", \"Time\"]},\n",
    "    infer_datetime_format=True\n",
    ")\n",
    "\n",
    "power_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03111217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075259, 8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87cfe1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2075259 entries, 0 to 2075258\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   datetime               datetime64[ns]\n",
      " 1   Global_active_power    float64       \n",
      " 2   Global_reactive_power  float64       \n",
      " 3   Voltage                float64       \n",
      " 4   Global_intensity       float64       \n",
      " 5   Sub_metering_1         float64       \n",
      " 6   Sub_metering_2         float64       \n",
      " 7   Sub_metering_3         float64       \n",
      "dtypes: datetime64[ns](1), float64(7)\n",
      "memory usage: 126.7 MB\n"
     ]
    }
   ],
   "source": [
    "cols = power_df.columns\n",
    "power_df[cols[1:]] = power_df[cols[1:]].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "power_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14f70a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_df.to_csv(\"power_raw_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f955e8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'power_raw_cleaned.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m power_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpower_raw_cleaned.parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\pandas\\io\\parquet.py:669\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    666\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    667\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\pandas\\io\\parquet.py:258\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    257\u001b[39m     to_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33msplit_blocks\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    265\u001b[39m     pa_table = \u001b[38;5;28mself\u001b[39m.api.parquet.read_table(\n\u001b[32m    266\u001b[39m         path_or_handle,\n\u001b[32m    267\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    270\u001b[39m         **kwargs,\n\u001b[32m    271\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\pandas\\io\\parquet.py:141\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    131\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    134\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    145\u001b[39m     path_or_handle = handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Moringa School\\anaconda3\\envs\\learn-env\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'power_raw_cleaned.parquet'"
     ]
    }
   ],
   "source": [
    "power_df = pd.read_parquet(\"power_raw_cleaned.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
